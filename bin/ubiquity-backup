#!/usr/bin/env ruby
lib_path = File.expand_path('../../lib', __FILE__)
$:.unshift(lib_path) unless $:.include?(lib_path) or !File.exists?(lib_path)

require 'rubygems'
require 'fileutils'
require 'logger'
require 'optparse'
require 'shellwords'
# require 'tempfile'

@archive_aspera_console = true
def archive_aspera_console?; @archive_aspera_console end

@archive_aspera_enterprise = true
def archive_aspera_enterprise?; @archive_aspera_enterprise end

@archive_aspera_faspex = true
def archive_aspera_faspex?; @archive_aspera_faspex end

@archive_aspera_orchestrator = true
def archive_aspera_orchestrator?; @archive_aspera_orchestrator end

@archive_aspera_shares = true
def archive_aspera_shares?; @archive_aspera_shares end

@archive_cantemo_portal = true
def archive_cantemo_portal?; @archive_cantemo_portal end

@archive_dir_base_path = '/tmp' # Dir.tmpdir
def archive_dir_base_path; @archive_dir_base_path end

@archive_name = "ubiquity-backup-#{Time.now.strftime('%Y%m%d')}-#{$$}-#{rand(0x100000000).to_s(36)}"
def archive_name; @archive_name end

@dry_run = true
def dry_run?; @dry_run end

def banner_footer
  <<-BANNER
System Names:
  all (default)
  aspera_console
  aspera_enterprise
  aspera_faspex
  aspera_orchestrator
  aspera_shares
  cantemo_portal

  * Note: Supplying a system name will override a --no-[system-name] option
  BANNER
end

op = OptionParser.new
op.program_name = File.basename($0)
op.banner = <<-BANNER
Usage: #{op.program_name} [options] [system name(s)]

Examples:

  1. Dry Run of a Backup of All Supported Systems (Default)
    # #{op.program_name}

  2. Actual Backup of All Supported Systems
    # #{op.program_name} --no-dry-run

  3. Backup Just Cantemo Portal
    # #{op.program_name} cantemo_portal --no-dry-run

  4. Backup Aspera Enterprise and Aspera Shares Only
    # #{op.program_name} --no-dry-run aspera_enterprise aspera_shares

Options:
BANNER
op.on('--[no-]archive-aspera-console', 'If set to false then an attempt to backup this system will not be made.', "default: #{archive_aspera_console?}\n\n" ) { |v| @archive_aspera_console = v }
op.on('--[no-]archive-aspera-enterprise', 'If set to false then an attempt to backup this system will not be made.', "default: #{archive_aspera_enterprise?}\n\n" ) { |v| @archive_aspera_enterprise = v }
op.on('--[no-]archive-aspera-faspex', 'If set to false then an attempt to backup this system will not be made.', "default: #{archive_aspera_faspex?}\n\n" ) { |v| @archive_aspera_faspex = v }
op.on('--[no-]archive-aspera-orchestrator', 'If set to false then an attempt to backup this system will not be made.', "default: #{archive_aspera_orchestrator?}\n\n" ) { |v| @archive_aspera_orchestrator = v }
op.on('--[no-]archive-aspera-shares', 'If set to false then an attempt to backup this system will not be made.', "default: #{archive_aspera_shares?}\n\n" ) { |v| @archive_aspera_shares = v }
op.on('--[no-]archive-cantemo-portal', 'If set to false then an attempt to backup this system will not be made.', "default: #{archive_cantemo_portal?}\n\n" ) { |v| @archive_cantemo_portal = v }
op.on('--archive-path PATH', 'The directory to use when building the archive.', "default: '#{archive_dir_base_path}'\n\n") { |v| puts "Setting Archive Path: '#{v}'"; @archive_dir_base_path = v }
op.on('--archive-name NAME', 'Will override the generated archive name with whatever is specified.', "example: #{archive_name}\n\n") { |v| @archive_name = v }
op.on('--[no-]dry-run', 'Will output the commands to be run but will not execute them.', "default: #{dry_run?}\n\n") { |v| @dry_run = v }
op.on('--help', 'Display this message.') { puts op; puts banner_footer; exit }
op.parse!

# Look for specific systems being passes as arguments
unless ARGV.empty?
  @archive_aspera_console = false
  @archive_aspera_enterprise = false
  @archive_aspera_faspex = false
  @archive_aspera_orchestrator = false
  @archive_aspera_shares = false
  @archive_cantemo_portal = false
end

ARGV.each do |val|
  _val = val.downcase
  case _val
    when 'all'
      @archive_aspera_console = true
      @archive_aspera_enterprise = true
      @archive_aspera_faspex = true
      @archive_aspera_orchestrator = true
      @archive_aspera_shares = true
      @archive_cantemo_portal = true
    when 'aspera_console';      @archive_aspera_console       = true
    when 'aspera_enterprise';   @archive_aspera_enterprise    = true
    when 'aspera_faspex';       @archive_aspera_faspex        = true
    when 'aspera_orchestrator'; @archive_aspera_orchestrator  = true
    when 'aspera_shares';       @archive_aspera_shares        = true
    when 'cantemo_portal';      @archive_cantemo_portal       = true
    else
      abort <<-ERRMSG
      Unknown System Name: #{_val}
      Known System Names:
        all
        aspera_console
        aspera_enterprise
        aspera_faspex
        aspera_orchestrator
        aspera_shares
        cantemo_portal
      ERRMSG
  end

end


class MultiIO
  def initialize(*targets); @targets = targets end
  def write(*args); @targets.each { |t| t.write(*args) rescue nil } end
  def close; @targets.each(&:close) end
  def add_target(target); @targets << target end
  def targets; @targets end
end


class Logger
  def add_target(target)
    _target = target.is_a?(String) ? File.open(target, 'a') : target
    @logdev.dev.add_target(_target) if @logdev.dev.respond_to?(:add_target)
  end
end

def execute(command_line, options = { })
  noop = options.fetch(:noop, default_noop)

  command_line = command_line.shelljoin if command_line.is_a?(Array)

  (@command_history ||= [ ]) << command_line

  unless noop
    logger.info { "Executing Command Line: #{command_line}" }
    `#{command_line}`
  end
end

def echo(message, options = { })
  if dry_run?
    execute(%(echo "#{message}"))
  else
    puts message
  end
end


def archive_aspera_console(task = { })
  console_backup_dir_path = '/opt/aspera/console/backup/'

  command_line = %(asctl console:backup_database)
  execute(command_line)

  tar_command_line = build_tar_command_line(:name => 'aspera_console_database', :path => '$NEW_ARCHIVE_DIR')
  command_line = %(export NEW_ARCHIVE_DIR=$(find "#{console_backup_dir_path}" -mindepth 1 -maxdepth 1 -type d | tail -1);#{tar_command_line};unset NEW_ARCHIVE_DIR)
  execute(command_line)

end

# def archive_aspera_connect(task = { })
#   configuration_file_path = task[:configuration_file_path] || '/Library/Aspera/etc/aspera.conf'
#   shares_backup_executable_path = task[:backup_executable_path] || '/opt/aspera/shares/u/setup/bin/backup'
#
#   archive_path(:name => 'aspera_connect_config', :path => configuration_file_path)
#   execute(%("#{shares_backup_executable_path}" -b "#{temp_dir}"))
# end

def archive_aspera_enterprise(task = { })

  # we put the enterprise backup into it's own path so that we can find the directory that it creates
  aspera_enterprise_archive_dir = File.join(archive_dir, 'aspera_enterprise_archive')
  execute(%(mkdir -p "#{aspera_enterprise_archive_dir}"))

  configuration_file_path = task[:configuration_file_path] || '/opt/aspera/etc/aspera.conf'
  shares_backup_executable_path = task[:backup_executable_path] || '/opt/aspera/bin/asnodeadmin'

  archive_path(:name => 'aspera_connect_config', :path => configuration_file_path)
  execute(%("#{shares_backup_executable_path}" -b "#{aspera_enterprise_archive_dir}"))

end

def archive_aspera_faspex(task = { })
  console_backup_dir_path = '/opt/aspera/console/backup/'

  command_line = %(asctl faspex:backup_database)
  execute(command_line)

  tar_command_line = build_tar_command_line(:name => 'aspera_faspex_database', :path => '$NEW_ARCHIVE_DIR')
  command_line = %(export NEW_ARCHIVE_DIR=$(find "#{console_backup_dir_path}" -mindepth 1 -maxdepth 1 -type d | tail -1);#{tar_command_line};unset NEW_ARCHIVE_DIR)
  execute(command_line)
end

def archive_aspera_orchestrator(task = { })
  _archive_name = task[:archive_name] || archive_name
  commands = [ ]
  commands << 'export GEM_HOME="/opt/aspera/orchestrator/vendor/dependencies/linux-gnu"'
  commands << 'cd /opt/aspera/orchestrator'
  commands << %(ruby script/runner 'FileUtils.cp(Snapshot.config_dump("#{_archive_name}").path, "#{archive_dir}")')
  execute(commands.join(';'))
end

def archive_aspera_shares(task = { })

  # we put the shares backup into it's own path so that we can find the directory that it creates
  aspera_shares_archive_dir = File.join(archive_dir, 'aspera_shares_archive')
  execute(%(mkdir -p "#{aspera_shares_archive_dir}"))

  shares_backup_executable_path = task[:backup_executable_path] || '/opt/aspera/shares/u/setup/bin/backup'
  execute(%("#{shares_backup_executable_path}" -b "#{aspera_shares_archive_dir}"))
end

def archive_elasticsearch_index(args = { })
  # http://stackoverflow.com/questions/12835937/elasticsearch-hot-backup-strategies
  # https://github.com/meskyanichi/backup/pull/433/files
  #
  # http://www.elastic.co/guide/en/elasticsearch/reference/master/indices-open-close.html
  # https://gist.github.com/nherment/1939828
  # http://www.elastic.co/guide/en/elasticsearch/reference/current/modules-snapshots.html
  # http://chrissimpson.co.uk/elasticsearch-snapshot-restore-api.html
  # https://www.google.com/search?q=elasticsearch+backup+index+sh&oq=elasticsearch+backup
  # https://karussell.wordpress.com/2011/07/10/how-to-backup-elasticsearch-with-rsync/
  task = args.dup

  gzip = args.fetch(:gzip, true)

  target_full_file_path = args[:target_full_file_path] || File.join(archive_dir, "#{task[:name]}#{gzip ? '.tgz' : '.tar'}")
  index = args[:index] || 'all'
  path = args[:path]

  host = args[:host] || 'localhost'
  port = args[:port] || 9200


end

def archive_mysql_database(task = { })
  # http://dev.mysql.com/doc/refman/5.6/en/mysqldump.html

  args = task[:database]

  mysqldump_executable_path = args[:mysqldump_executable_path] || 'mysqldump'

  hostname = args.fetch(:hostname, false)
  port = args.fetch(:port, false)
  username = args.fetch(:username, false)
  password = args.fetch(:password, false)
  database_name = args[:name]

  gzip = args.fetch(:gzip, true)

  table_list = args[:table_list] || [ ]
  table_list = [ table_list ] unless table_list.is_a?(Array)
  table_name = args[:table_name]
  table_list << table_name if table_name

  target_full_file_path = args[:target_full_file_path] || File.join(archive_dir, "#{task[:name]}#{gzip ? '.tgz' : '.sql'}")

  command_line = [ mysqldump_executable_path ]
  command_line << '-h' << hostname if hostname
  command_line << '-P' << port if port
  command_line << '-u' << username if username
  command_line << "-p#{password}" if password
  #command_line << "--databases #{database_name}" if database_name
  command_line << database_name if database_name
  command_line = command_line +  table_list unless table_list.empty?
  command_line = command_line.shelljoin
  command_line << " > #{target_full_file_path}"
  #command_line = %("#{mysqldump_executable_path}" #{username ? " --user=#{username}" : ''}#{password ? " -password=#{password}" : ''}#{hostname ? " -h#{hostname}" : ''}#{port ? " --port=#{port}" : ''}#{table_list ? " #{table_list.join(' ')}" : ''} #{database_name} > #{target_full_file_path} )


  execute(command_line)
end

def determine_archive_path(args = { })

end

def build_tar_command_line(args = { })
  name = args[:name]
  path = args[:path]
  use_relative_path = args.fetch(:use_relative_path, true)
  file_name = "#{name}.tgz"
  if use_relative_path
    prefix = %(cd "#{archive_dir}";)
    target_file_path = file_name
  else
    prefix = ''
    target_full_file_path = args[:target] || File.join(archive_dir, file_name)
    target_file_path = target_full_file_path
  end

  use_sudo = args.fetch(:use_sudo, true)

  #logger.info { "Archiving Path: '#{path}' Name: #{name}" }
  # `tar cvzf cantemo_portal_configs.tgz /opt/cantemo/portal/configs`
  # `tar cvzf cantemo_portal_configs.tgz /opt/cantemo/portal/configs`

  %(#{prefix}#{use_sudo ? 'sudo ' : ''}tar czvf "#{target_file_path}" "#{path}")
end

def archive_path(args = { })
  command_line = build_tar_command_line(args)
  execute(command_line)
end

def archive_postgresql_database(task = { })
  args = task[:database]

  # http://www.postgresql.org/docs/8.4/static/continuous-archiving.html#BACKUP-ARCHIVING-WAL
  # http://www.postgresql.org/docs/8.0/static/backup.html
  # Copy Databases
  # WAL Logs
  pg_dump_executable_path = args[:pg_dump_executable_path] || '/usr/bin/pg_dump'

  hostname = args.fetch(:hostname, 'localhost')
  username = args.fetch(:username, 'postgres')
  password = args.fetch(:password, false)
  database_name = args[:name]

  target_full_file_path = args[:target_full_file_path] || File.join(archive_dir, "#{task[:name]}.sql")

  #command_line = %("#{pg_dump_executable_path}"#{hostname ? " -h #{hostname}" : ''}#{username ? " -U #{username}" : ''} #{database_name} | gzip > "#{target_full_file_path}")
  command_line = %(#{password ? "export PGPASSWORD=#{password};" : ''}"#{pg_dump_executable_path}"#{hostname ? " -h #{hostname}" : ''}#{username ? " -U #{username}" : ''} #{database_name} > "#{target_full_file_path}";unset PGPASSWORD)
  execute(command_line)

  { :files => [ target_full_file_path ] }
end

def archive_redis_database(args = { })

end

def archive_solr_index(args = { })
  # https://cwiki.apache.org/confluence/display/solr/Backing+Up
end

@arguments = { }
def arguments; @arguments end

@default_noop = dry_run?
def default_noop; @default_noop end

@output_command_history = true
def output_command_history?; @output_command_history end

@logger = Logger.new(arguments[:log_to] || MultiIO.new(STDOUT))
def logger; @logger end
logger.level = arguments[:log_level] || Logger::INFO

@archive_file_name = "#{archive_name}.tgz"
def archive_file_name; @archive_file_name end

@archive_dir = File.join(archive_dir_base_path, archive_name)
def archive_dir; @archive_dir end

@log_file_path = File.join(archive_dir, 'backup.log')
def log_file_path; @log_file_path end

@preserved_working_dir = Dir.pwd
def preserved_working_dir; @preserved_working_dir end

FileUtils.mkdir_p(archive_dir_base_path) unless dry_run?

execute("mkdir -p #{archive_dir}")
execute("cd #{archive_dir}")

logger.debug { "Archive Dir: #{archive_dir}" }
logger.add_target(log_file_path) if !dry_run? and logger.respond_to?(:add_target)

class BaseArchive

  TASKS = [ ]

  def self.tasks; self::TASKS.dup end
  def self.tasks_by_name(tasks = self::TASKS); Hash[tasks.map { |task| [ task[:name], task] }] end

  def tasks; @tasks ||= TASKS.dup end
  def tasks_by_name; self.class.tasks_by_name end

end

# @existing_constants = Object.constants

# class AsperaConnectServerArchive < BaseArchive
# # @see http://download.asperasoft.com/download/docs/entsrv/3.5.4/cs_admin_linux/pdf2/ConnectServer_Admin_3.5.4_Linux.pdf
#
# # @see http://download.asperasoft.com/download/docs/entsrv/3.5.4/cs_admin_osx/pdf2/ConnectServer_Admin_3.5.4_OSX.pdf
#
# =begin
#   /Library/Aspera/etc
#   /Library/Aspera/etc/aspera.conf
#
#   Redis DB Backup/Restore
#     Instructions for backing up and restoring the database.
#
#     To back up and restore the Redis database (and your user data up to the point-in-time of the backup operation), follow
#     the instructions below. Note that the backup and restore operations should be used for the following scenarios:
#
#     • If you need to change the Redis database port number (<db_port/> in aspera.conf), you should first back up
#     the Redis database. Once you have changed the port number, you need to restore the database.
#     • Basic backup and restore (after a data-loss event).
#
#     1. Back up the Redis database.
#         Use the following command to back up your Redis database (before changing the port number):
#         $ sudo /Library/Aspera/bin/asnodeadmin -b /your/backup/dir/
#         database.backup
#         Important: When backing up the Redis database, all user data up to that point-in-time will be saved to
#         the backup file. Restoring the database (see Step 2, below) does not delete users added after this snapshot
#         was taken. Thus, if you added any users after backing up the database, then they will still exist in the
#         system and will not be affected by the restore operation.
#
#     2. Restore the Redis database.
#         Use the following command to restore your Redis database:
#         $ sudo /Library/Aspera/bin/asnodeadmin -r /your/backup/dir/
#         database.backup
#         Recall the "Important Note" in Step 1, which stated that restoring the database does not delete users added after
#         the database snapshot was taken. If you do not want to keep users that have been added since the last backup
#         operation, you can delete them after performing the restore with the asnodeadmin command -du username.
#
#     3. Restart the asperanoded service.
#         Use the following command(s) to restart the asperanoded service (requires a restart rather than a reload):
#         $ sudo launchctl stop com.aspera.asperanoded
#         $ sudo launchctl start com.aspera.asperanoded
# =end
#
#   TASKS = [
#     { :type => :archive_path, :name => 'aspera_connect_config', :path => '/opt/aspera/etc' },
#     #{ :type => :execute, :name => 'aspera_connect_db', :path => '/opt/aspera/shares/u/setup/bin/backup' }
#   ]
#
# end

class AsperaConsoleServerArchive < BaseArchive
  # @see http://download.asperasoft.com/download/docs/console/2.5.1/admin_linux/webhelp/index.html#dita/backing_up_console_database.html

  TASKS = [
    { :type => :archive_aspera_console },

    # None of the paths are in the documentation but did show up when the
    # { :type => :archive_path, :name => 'aspera_common_apache_config', :path => '/opt/aspera/common/apache/apache.rb.yml' },
    # { :type => :archive_path, :name => 'aspera_common_mysql_config', :path => '/opt/aspera/common/mysql/mysql.rb.yml' },
    # { :type => :archive_path, :name => 'aspera_console_config_file', :path => '/opt/aspera/console/console.rb.yml' },
    # { :type => :archive_path, :name => 'aspera_console_config_dir', :path => '/opt/aspera/console/config' },

    { :type => :archive_path, :name => 'aspera_common_dir', :path => '/opt/aspera/common' },
    { :type => :archive_path, :name => 'aspera_console_dir', :path => '/opt/aspera/console' },


  ]

end

class AsperaEnterpriseServerArchive < BaseArchive
# @see http://download.asperasoft.com/download/docs/entsrv/3.5.4/es_admin_linux/pdf2/EnterpriseServer_Admin_3.5.4_Linux.pdf

=begin
  /opt/aspera/etc/
  /opt/aspera/etc/aspera.conf

  Redis DB Backup/Restore
    Instructions for backing up and restoring the database.
    To back up and restore the Redis database (and your user data up to the point-in-time of the backup operation), follow
    the instructions below. Note that the backup and restore operations should be used for the following scenarios:

    • If you need to change the Redis database port number (<db_port/> in aspera.conf), you should first back up
      the Redis database. Once you have changed the port number, you need to restore the database.
    • Basic backup and restore (after a data-loss event).

    1. Back up the Redis database.
        Use the following command to back up your Redis database (before changing the port number):
        $ sudo /opt/aspera/bin/asnodeadmin -b /your/backup/dir/database.backup
        Important: When backing up the Redis database, all user data up to that point-in-time will be saved to
        the backup file. Restoring the database (see Step 2, below) does not delete users added after this snapshot
        was taken. Thus, if you added any users after backing up the database, then they will still exist in the
        system and will not be affected by the restore operation.

    2. Restore the Redis database.
        Use the following command to restore your Redis database:
        $ sudo /opt/aspera/bin/asnodeadmin -r /your/backup/dir/database.backup
        Recall the "Important Note" in Step 1, which stated that restoring the database does not delete users added after
        the database snapshot was taken. If you do not want to keep users that have been added since the last backup
        operation, you can delete them after performing the restore with the asnodeadmin command -du username.

    3. Restart the asperanoded service.
        Use the following command(s) to restart the asperanoded service (requires a restart rather than a reload):
        $ sudo /etc/init.d/asperanoded restart
=end

  TASKS = [
      { :type => :archive_aspera_enterprise },
      { :type => :archive_path, :name => 'aspera_enterprise_config', :path => '/opt/aspera/etc' },
  ]


end

class AsperaFaspexArchive < BaseArchive
  # @see http://download.asperasoft.com/download/docs/faspex/3.9.1/admin_linux/webhelp/index.html#dita/backup.html

  TASKS = [

    { :type => :archive_aspera_faspex },

    { :type => :archive_path, :name => 'aspera_faspex_config', :path => '/opt/aspera/faspex.rb.yml' },
    { :type => :archive_path, :name => 'aspera_faspex_config_dir_yml', :path => '/opt/aspera/config/*.yml' },
    { :type => :archive_path, :name => 'aspera_faspex_config_license', :path => '/opt/aspera/config/aspera.faspex.*.aspera-license' },
    { :type => :archive_path, :name => 'aspera_faspex_config_mongrel_cluster', :path => '/opt/aspera/config/mongrel_cluster/mongrel_cluster.yml' },

  ]

end

class AsperaSharesArchive < BaseArchive
# @see http://download.asperasoft.com/download/docs/shares/1.9.1/admin_linux/pdf2/Shares_Admin_1.9.1_Linux.pdf

=begin

    1. Run the following script as a root user.
        The script stops Shares services, backs up all necessary files, and restarts Shares. You cannot use this procedure
        with earlier versions of Shares.
        # /opt/aspera/shares/u/setup/bin/backup /your_backup_dir
        For example:
        # /opt/aspera/shares/u/setup/bin/backup /tmp
        Creating backup directory /tmp/20130627025459 ...
        Checking status of aspera-shares ...
        Status is running
        mysqld is alive
        Backing up the Shares database and config files ...
        Backing up the SSL certificates ...
        Done
    2. Make a note of the ID of the created backup directory for future use. In the above example example:
        20130627025459
=end
  TASKS = [
      # { :type => :execute, :name => 'aspera_shares_backup_script', :path => '/opt/aspera/shares/u/setup/bin/backup' }
      { :type => :archive_aspera_shares, :name => 'aspera_shares_backup' }
  ]

end

class CantemoPortalArchive < BaseArchive

  # require 'inifile'

  TASKS = [

      # Paths
      { :type => :archive_path, :name => 'cantemo_portal_configs',            :path => '/opt/cantemo/portal/configs' },
      { :type => :archive_path, :name => 'cantemo_portal_elasticsearch_conf', :path => '/etc/elasticsearch' },
      { :type => :archive_path, :name => 'cantemo_portal_etc',                :path => '/etc/cantemo/portal/' },
      { :type => :archive_path, :name => 'cantemo_portal_glassfish_domain',   :path => '/opt/glassfish3/glassfish/domains/domain1/config/domain.xml' },
      { :type => :archive_path, :name => 'cantemo_portal_glassfish_solr',     :path => '/opt/glassfish3/glassfish/solrhome' },
      { :type => :archive_path, :name => 'cantemo_portal_media',              :path => '/opt/cantemo/portal/portal_media' },
      { :type => :archive_path, :name => 'cantemo_portal_nginx',              :path => '/etc/nginx/conf.d/portal.conf' },
      { :type => :archive_path, :name => 'cantemo_portal_rabbitmq',           :path => '/var/lib/rabbitmq' },
      { :type => :archive_path, :name => 'cantemo_portal_rabbitmq_conf',      :path => '/etc/rabbitmq' },
      { :type => :archive_path, :name => 'cantemo_portal_themes',             :path => '/opt/cantemo/portal/portal_themes' },
      { :type => :archive_path, :name => 'cantemo_portal_thumbnails',         :path => '/srv/thumbnail' },
      { :type => :archive_path, :name => 'cantemo_portal_usermedia',          :path => '/opt/cantemo/portal/usermedia' },

      # Postgres Databases
      { :type => :archive_postgresql_database, :name => 'cantemo_portal_db', :database => { :name => 'portal', :username => 'postgres', :password => 'postgres' } },
      { :type => :archive_postgresql_database, :name => 'cantemo_vidispine_db', :database => { :name => 'vidispine', :username => 'postgres', :password => 'postgres' } },

      # Nginx
      # /etc/nginx/conf.d/portal.conf

      # Glassfish
      # /opt/glassfish3/glassfish/domains/domain1/config/domain.xml

      # Solr Home in Glassfish
      # /opt/glassfish3/glassfish/solrhome

      # Elasticsearch
      # /etc/elasticsearch/
      { :type => :archive_elasticsearch_index, :name => 'cantemo_portal_elasticsearch' }

      # RabbitMQ
      # /var/lib/rabbitmq
      # /etc/rabbitmq/
  ]

  # def self.tasks
  #   self.new.tasks
  # end

  # def initialize(args = { })
  #   _tasks_by_name = tasks_by_name
  #
  #   cantemo_portal_config_path = File.join(_tasks_by_name['cantemo_portal_configs'][:path], 'portal.conf')
  #   cantemo_portal_config = IniFile.load(cantemo_portal_config_path)
  #
  #   cantemo_portal_database_config = cantemo_portal_config['database']
  #   return tasks if cantemo_portal_database_config.empty?
  #
  #   cantemo_portal_database_name = cantemo_portal_database_config['DATABASE_NAME']
  #   cantemo_portal_database_host = cantemo_portal_database_config['DATABASE_HOST']
  #   cantemo_portal_database_port = cantemo_portal_database_config['DATABASE_PORT']
  #   cantemo_portal_database_username = cantemo_portal_database_config['DATABASE_USER']
  #   cantemo_portal_database_password = cantemo_portal_database_config['DATABASE_PASSWORD']
  #
  #   cantemo_portal_archive_database_config = {
  #     :hostname => cantemo_portal_database_host,
  #     :port => cantemo_portal_database_port,
  #     :name => cantemo_portal_database_name,
  #     :username => cantemo_portal_database_username,
  #     :password => cantemo_portal_database_password
  #   }
  #
  #   _tasks_by_name['cantemo_portal_db'][:database].merge!(cantemo_portal_archive_database_config)
  #
  #   # Get Portal Database Information
  #   @tasks = _tasks_by_name.map { |_, task| task }
  # end

end

class AsperaOrchestratorArchive < BaseArchive

  TASKS = [

    { :type => :archive_aspera_orchestrator },

    { :type => :archive_path, :name => 'orchestrator_apache_config', :path => '/opt/aspera/common/apache/conf' },
    { :type => :archive_path, :name => 'orchestrator_mysql_config', :path => '/opt/aspera/common/mysql/my.ini' },
    # MySQL Configuration


    # { :type => :archive_path, :name => 'orchestrator_config', :path => '/opt/aspera/orchestrator/var/config' },
    #
    # { :type => :archive_mysql_database, :name => 'orchestrator_db', :database => { :name => 'orchestrator', :port => '4406', :username => 'mysql', :password => 'aspera' } }

    # Portlets
    { :type => :archive_path, :name => 'orchestrator_aspera_portlets', :path => '/opt/aspera/orchestrator/portlets' },
    { :type => :archive_path, :name => 'orchestrator_aspera_portlets_in_var_config', :path => '/opt/aspera/var/config/orchestrator/portlets' },

    # /opt/aspera/orchestrator/portlets
    # /opt/aspera/var/config/orchestrator/portlets

  ]
end

# backup_tasks = OrchestratorArchive.tasks
# backup_tasks = CantemoPortalArchive.tasks + AsperaOrchestratorArchive.tasks
#backup_tasks = (Object.constants - @existing_constants).delete_if { |obj| !Object.const_get(obj).respond_to?(:tasks) }.map { |obj| Object.const_get(obj).tasks }.flatten

to_archive = [ ]
to_archive << AsperaConsoleServerArchive if archive_aspera_console?
to_archive << AsperaEnterpriseServerArchive if archive_aspera_enterprise?
to_archive << AsperaFaspexArchive if archive_aspera_faspex?
to_archive << AsperaOrchestratorArchive if archive_aspera_orchestrator?
to_archive << AsperaSharesArchive if archive_aspera_shares?
to_archive << CantemoPortalArchive if archive_cantemo_portal?

begin
  to_archive.each do |archive|
    echo "# ### #{archive.name} start ###"
    backup_tasks = archive.tasks

    logger.debug { "Tasks: (#{backup_tasks.length}) #{backup_tasks.inspect}" }
    backup_tasks.each do |task|
      logger.debug { "Processing Task: #{task.inspect}" }
      case task[:type]
        # when :archive_aspera_connect; archive_aspera_connect(task)
        when :archive_aspera_console; archive_aspera_console(task)
        when :archive_aspera_faspex; archive_aspera_faspex(task)
        when :archive_aspera_enterprise; archive_aspera_enterprise(task)
        when :archive_aspera_orchestrator; archive_aspera_orchestrator(task)
        when :archive_aspera_shares; archive_aspera_shares(task)
        # when :archive_elasticsearch_index; archive_elasticsearch_index(task)
        # when :archive_mysql_database; archive_mysql_database(task)
        when :archive_path; archive_path(task)
        when :archive_postgresql_database; archive_postgresql_database(task)
        # when :archive_redis_database; archive_redis_database(task)
      end
    end
    echo "# ### #{archive.name} end ###"
  end

  execute(%(cd "#{archive_dir_base_path}";tar czvf "#{archive_file_name}" "#{archive_name}"))
  echo %(Archive Created: '#{File.join(archive_dir_base_path, archive_file_name)}')

ensure
  logger.info { "Command#{dry_run? ? 's (Dry Run)' : ' History'}:\n#{@command_history.join("\n")}" } if (dry_run? || output_command_history?)
  Dir.chdir(preserved_working_dir)
end

